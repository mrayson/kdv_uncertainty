{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit harmonics to filtered $A_n$ data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc3 as pm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import h5py\n",
    "\n",
    "#from soda.dataio.conversion import readotps\n",
    "\n",
    "from scipy.optimize import fmin_powell, fmin, fmin_cg, fmin_ncg\n",
    "\n",
    "from theano import shared\n",
    "from theano import tensor as tt\n",
    "import arviz as az\n",
    "\n",
    "from soda.utils.timeseries import timeseries, skill, rmse\n",
    "from soda.utils.uspectra import uspectra, getTideFreq\n",
    "from soda.utils.othertime import SecondsSince, TimeVector\n",
    "from mycurrents import oceanmooring as om\n",
    "from soda.utils.harmonic_analysis import harmonic_fit_array\n",
    "from soda.utils.mysignal import power_spectra\n",
    "\n",
    "from scipy import signal\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['font.size'] = 14\n",
    "mpl.rcParams['axes.labelsize'] = 'large'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ncfile = '/home/suntans/Share/ARCHub/DATA/FIELD/browse-basin-kissme/Data/NetCDF/KISSME_Fitted_Buoyancy_wout_motion.nc'\n",
    "ncfile = '/home/suntans/Share/ARCHub/DATA/FIELD/ShellCrux/KP150_Fitted_Buoyancy_wout_motion.nc'\n",
    "# ncfile = r'C:\\Projects\\ARCHub\\DATA\\FIELD\\ShellCrux\\KP150_Fitted_Buoyancy_wout_motion.nc'\n",
    "ds1 = xr.open_dataset(ncfile,group='KP150_phs1')\n",
    "ds2 = xr.open_dataset(ncfile,group='KP150_phs2')\n",
    "ds1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsample = 60\n",
    "subsample = 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter each time series and concatenate\n",
    "A1 = om.OceanMooring(ds1.time.values, ds1['A_n'][:,0],0.0)\n",
    "A2 = om.OceanMooring(ds2.time.values, ds2['A_n'][:,0],0.0)\n",
    "\n",
    "A1f = om.OceanMooring(A1.t, A1.filt((34*3600, 6*3600), btype='band'), 0.0)\n",
    "A2f = om.OceanMooring(A2.t, A2.filt((34*3600, 6*3600), btype='band'), 0.0)\n",
    "\n",
    "A_n = A1f.concat(A2f)\n",
    "A_n_1h_6 = xr.DataArray(A_n.y[::subsample], dims=('time'), coords={'time':A_n.t[::subsample]})\n",
    "\n",
    "A1f = om.OceanMooring(A1.t, A1.filt((34*3600, 3*3600), btype='band'), 0.0)\n",
    "A2f = om.OceanMooring(A2.t, A2.filt((34*3600, 3*3600), btype='band'), 0.0)\n",
    "\n",
    "\n",
    "A_n = A1f.concat(A2f)\n",
    "A_n_1h = xr.DataArray(A_n.y[::subsample], dims=('time'), coords={'time':A_n.t[::subsample]})\n",
    "\n",
    "\n",
    "\n",
    "# A_n_1h.loc['2016-09-15':'2016-10-31']=np.nan\n",
    "\n",
    "#A_n_1h = A_n_1h.sel(time=slice('2016-11-02','2017-05-02'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "A_n_1h.plot(lw=0.25)\n",
    "A_n_1h_6.plot(lw=0.2)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Extract the daily maximum and save to h5 files (use as test input for kdv)\n",
    "def max_amplitude_finder(amp_signal):\n",
    "    if amp_signal.shape[0] == 0:\n",
    "        return 0,0\n",
    "    amp_min = np.nanmax(amp_signal)\n",
    "    return amp_min, np.argwhere(amp_signal==amp_min)[0][0]\n",
    "    \n",
    "def maximum_amplitude_finder(amp_signal):\n",
    "    if amp_signal.shape[0] == 0:\n",
    "        return 0,0\n",
    "    amp_min = np.nanmin(amp_signal)\n",
    "    amp_max = np.nanmax(amp_signal)\n",
    "    if np.abs(amp_min)>amp_max:\n",
    "        return amp_min, np.argwhere(amp_signal==amp_min)[0][0]\n",
    "    else:\n",
    "        return amp_max, np.argwhere(amp_signal==amp_max)[0][0]\n",
    "    \n",
    "rhotime = pd.date_range('2016-05-01','2017-05-02',freq='D').values\n",
    "tnew = rhotime\n",
    "tsecnew = SecondsSince(tnew,basetime=basetime)\n",
    "tdaynew = tsecnew/86400.\n",
    "nt = tnew.shape[0]\n",
    "\n",
    "Umax_all = []\n",
    "Umax_time = []\n",
    "for t1 in rhotime:\n",
    "    t2 = t1 + np.timedelta64(1,'D')\n",
    "    Umax, tidx = max_amplitude_finder(A_n_1h.sel(time=slice(t1,t2)).values)\n",
    "    Umax_all.append(Umax)\n",
    "\n",
    "#ds_A = pd.Series(Amax_all, index=Amax_time)\n",
    "ds_A = xr.DataArray(Umax_all, coords={'time':rhotime}, dims=('time',))\n",
    "\n",
    "plt.figure()\n",
    "ds_A.plot()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Save to hdf5\n",
    "nsamples = 500\n",
    "a0_pred = np.zeros((nsamples,nt))\n",
    "a0_pred[:,:] = ds_A.values\n",
    "\n",
    "outputh5 = '../inputs/a0_samples_bandpass_3h_12month.h5'.format(sitename)\n",
    "\n",
    "\n",
    "f = h5py.File(outputh5,'w')\n",
    "g = f.create_group('data')\n",
    "g.create_dataset('a0-all-times-samples',data=a0_pred.T)\n",
    "g.create_dataset('time',data=tdaynew)\n",
    "g.create_dataset('dtime64',data=tnew.view(int))\n",
    "f.close()\n",
    "print(outputh5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sine_model(beta_s, ff, t):\n",
    "    n = len(ff)\n",
    "\n",
    "    result = beta_s[0]*np.ones_like(t)\n",
    "    for ii in range(0,n):\n",
    "        result += beta_s[2*ii+1]*np.cos(ff[ii] * t) + beta_s[2*ii+2]*np.sin(ff[ii]*t)\n",
    "\n",
    "    return result\n",
    "\n",
    "def sine_model_pm(beta_s, ff, t):\n",
    "    n = len(ff)\n",
    "\n",
    "    result = beta_s[0] + beta_s[1]*t\n",
    "    for ii in range(0,n):\n",
    "        result += beta_s[2*ii+2]*pm.math.cos(ff[ii] * t) + beta_s[2*ii+3]*pm.math.sin(ff[ii]*t)\n",
    "\n",
    "    return result\n",
    "\n",
    "def sine_model_notrend_pm(beta_s, ff, t):\n",
    "    n = len(ff)\n",
    "    \n",
    "    result = beta_s[0]+0*t\n",
    "    for ii in range(0,n):\n",
    "        result += beta_s[2*ii+1]*pm.math.cos(ff[ii] * t) + beta_s[2*ii+2]*pm.math.sin(ff[ii]*t)\n",
    "\n",
    "    return result\n",
    "    \n",
    "def cosine_model_pm(beta_s, ff, t):\n",
    "    n = len(ff)\n",
    "    \n",
    "    result = beta_s[0]+0*t\n",
    "    for ii in range(0,n):\n",
    "        result += beta_s[2*ii+1]*pm.math.cos(ff[ii] * t - beta_s[2*ii+2])\n",
    "\n",
    "    return result\n",
    "\n",
    "def sine_model_notrend(beta_s, ff, t):\n",
    "    n = len(ff)\n",
    "    \n",
    "    result = beta_s[0] + 0*t\n",
    "    for ii in range(0,n):\n",
    "        result += beta_s[2*ii+1]*np.cos(ff[ii] * t) + beta_s[2*ii+2]*np.sin(ff[ii]*t)\n",
    "\n",
    "    return result    \n",
    "\n",
    "def sine_model_envelope(beta_s, ff, t):\n",
    "    n = len(ff)\n",
    "    \n",
    "    #result = t*0\n",
    "    \n",
    "    #result = np.zeros(t.shape)\n",
    "    result = beta_s[0] + 0*t\n",
    "\n",
    "    for ii in range(0,n):\n",
    "        result += beta_s[2*ii+1]*np.cos(ff[ii] * t) + beta_s[2*ii+2]*np.sin(ff[ii]*t)\n",
    "        \n",
    "    # Compute the imaginary part by adding a 90 degree phase shift\n",
    "    #result_i = t*0\n",
    "    result_i = np.zeros(t.shape) # Imaginary mean component is zero\n",
    "\n",
    "    for ii in range(0,n):\n",
    "        result_i += beta_s[2*ii+1]*np.cos(ff[ii] * t + np.pi/2) \\\n",
    "            + beta_s[2*ii+2]*np.sin(ff[ii]*t + np.pi/2)\n",
    "    \n",
    "    return np.sqrt(result*result + result_i*result_i)\n",
    "\n",
    "# def sine_model_envelope_pm(beta_s, ff, t):\n",
    "#     n = len(ff)\n",
    "    \n",
    "#     #result = t*0\n",
    "    \n",
    "#     result = tt.zeros(t.shape)\n",
    "\n",
    "#     for ii in range(0,n):\n",
    "#         result += beta_s[2*ii]*pm.math.cos(ff[ii] * t) + beta_s[2*ii+1]*pm.math.sin(ff[ii]*t)\n",
    "        \n",
    "#     # Compute the imaginary part by adding a 90 degree phase shift\n",
    "#     #result_i = t*0\n",
    "#     result_i = tt.zeros(t.shape)\n",
    "\n",
    "#     for ii in range(0,n):\n",
    "#         result_i += beta_s[2*ii]*pm.math.cos(ff[ii] * t + np.pi/2) \\\n",
    "#             + beta_s[2*ii+1]*pm.math.sin(ff[ii]*t + np.pi/2)\n",
    "    \n",
    "#     return pm.math.sqrt(result*result + result_i*result_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function with similar functionality as harmonic_fit in soda\n",
    "def harmonic_fit_mcmc(time, X, frq, mask=None, axis=0, basetime=None,         **kwargs):\n",
    "    \"\"\"\n",
    "    Harmonic fitting using Bayesian inference\n",
    "    \"\"\"\n",
    "    tday = 86400.\n",
    "    # Convert the time to days\n",
    "    dtime = SecondsSince(time, basetime=basetime )\n",
    "    \n",
    "    \n",
    "    # Generate initvalues from least-squares fitting\n",
    "    ts = timeseries(time, X)\n",
    "    amp, phs, _, _, h_lsq, err = ts.tidefit(frqnames=names)\n",
    "    \n",
    "    initvals = {'beta_mean':0.}\n",
    "    initvals = {'sigma':1.}\n",
    "\n",
    "    ii=-1\n",
    "    for aa, pp in zip(amp,phs):\n",
    "        ii+=1\n",
    "        initvals.update({'beta_amp_%d'%ii:aa})\n",
    "        initvals.update({'beta_phs_%d'%ii:pp})\n",
    "    print(initvals)\n",
    "\n",
    "    \n",
    "    dtime /= tday\n",
    "    \n",
    "    # Convert the frequencies to radians / day\n",
    "    omega = [ff*tday for ff in frq]\n",
    "    #omega = frq\n",
    "    \n",
    "    # Number of parameters\n",
    "    n_params = 2*len(omega) + 1\n",
    "    \n",
    "    print('Number of Parametrs: %d\\n'%n_params, omega)\n",
    "\n",
    "    with pm.Model() as my_model:\n",
    "        ###\n",
    "        # Create priors for each of our variables\n",
    "        BoundNormal = pm.Bound(pm.Normal, lower=0.0)\n",
    "\n",
    "        # Mean\n",
    "        beta_mean = pm.Normal('beta_mean', mu=0, sd=1)\n",
    "        # Trend\n",
    "        #beta_linear = pm.Normal('beta_linear', mu=0, sd=1.)\n",
    "\n",
    "        #beta_s = [beta_mean, beta_linear]\n",
    "        beta_s=[beta_mean]\n",
    "\n",
    "        # Harmonics\n",
    "        for n in range(0,2*len(omega),2):\n",
    "            beta_s.append(pm.Normal('beta_%d_re'%(n//2), mu=1., sd = 5.))\n",
    "            beta_s.append(pm.Normal('beta_%d_im'%(n//2), mu=1., sd = 5.))\n",
    "        #for n in range(0,len(omega)):\n",
    "        #    beta_s.append(BoundNormal('beta_amp_%d'%n,mu=1., sd=10.))\n",
    "        #    #beta_s.append(pm.Uniform('beta_amp_%d'%n,lower=0, upper=30))\n",
    "        #    beta_s.append(pm.Uniform('beta_phs_%d'%n, lower=-np.pi, upper=np.pi))\n",
    "\n",
    "        ###\n",
    "        # Generate the likelihood function using the deterministic variable as the mean\n",
    "        #mu_x = cosine_model_pm(beta_s, omega, dtime)\n",
    "        #mu_x = pm.Deterministic('mu_x', cosine_model_pm(beta_s, omega, dtime))\n",
    "        mu_x = sine_model_notrend_pm(beta_s, omega, dtime)\n",
    "\n",
    "        \n",
    "        #sigma = BoundNormal('sigma', mu=1.,sd=0.25)\n",
    "        sigma = pm.HalfNormal('sigma',5.)\n",
    "        \n",
    "        #sigma = 1.0\n",
    "        X_obs = pm.Normal('X_obs', mu=mu_x, sd=sigma, observed=X)\n",
    "        #X_obs = pm.Normal('X_obs', mu=mu_x, sd=1, observed=X)\n",
    "        \n",
    "        mp = pm.find_MAP()\n",
    "        print(mp)\n",
    "        # Inference step...\n",
    "        #step = pm.Metropolis()\n",
    "        #step = pm.NUTS()\n",
    "        step = None\n",
    "        start = None\n",
    "        trace = pm.sample(500, tune=1000, start = start, step=step, cores=2,\n",
    "                         )#nuts_kwargs=dict(target_accept=0.95, max_treedepth=16, k=0.5))\n",
    "    \n",
    "    \n",
    "    # Return the trace and the parameter stats\n",
    "    return trace,  my_model, omega, dtime, h_lsq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function with similar functionality as harmonic_fit in soda\n",
    "def harmonic_fit_mcmc_arn(time, X, frq, arn=1, mask=None, axis=0, basetime=None,         **kwargs):\n",
    "    \"\"\"\n",
    "    Harmonic fitting using Bayesian inference\n",
    "    \n",
    "    Model the errors using an auto-regressive model\n",
    "    \"\"\"\n",
    "    tday = 86400.\n",
    "    # Convert the time to days\n",
    "    dtime = SecondsSince(time, basetime=basetime )\n",
    "    nt = dtime.shape[0]\n",
    "    \n",
    "    \n",
    "    # Generate initvalues from least-squares fitting\n",
    "    ts = timeseries(time, X)\n",
    "    amp, phs, _, _, h_lsq, err = ts.tidefit(frqnames=names)\n",
    "    \n",
    "    initvals = {'beta_mean':0.}\n",
    "    initvals = {'sigma':1.}\n",
    "\n",
    "    ii=-1\n",
    "    for aa, pp in zip(amp,phs):\n",
    "        ii+=1\n",
    "        beta_re = amp*np.cos(phs)\n",
    "        beta_im = amp*np.sin(phs)\n",
    "        initvals.update({'beta_%d_re'%ii:aa})\n",
    "        initvals.update({'beta_%d_im'%ii:pp})\n",
    "    print(initvals)\n",
    "\n",
    "    \n",
    "    dtime /= tday\n",
    "    \n",
    "    # Convert the frequencies to radians / day\n",
    "    omega = [ff*tday for ff in frq]\n",
    "    #omega = frq\n",
    "    \n",
    "    # Number of parameters\n",
    "    n_params = 2*len(omega) + 1\n",
    "    \n",
    "    print('Number of Parametrs: %d\\n'%n_params, omega)\n",
    "\n",
    "    with pm.Model() as my_model:\n",
    "        ###\n",
    "        # Create priors for each of our variables\n",
    "        BoundNormal = pm.Bound(pm.Normal, lower=0.0)\n",
    "\n",
    "        # Mean\n",
    "        beta_mean = pm.Normal('beta_mean', mu=0, sd=1)\n",
    "        # Trend\n",
    "        #beta_linear = pm.Normal('beta_linear', mu=0, sd=1.)\n",
    "\n",
    "        #beta_s = [beta_mean, beta_linear]\n",
    "        beta_s=[beta_mean]\n",
    "\n",
    "        # Harmonics\n",
    "        for n in range(0,2*len(omega),2):\n",
    "            beta_s.append(pm.Normal('beta_%d_re'%(n//2), mu=1., sd = 5.))\n",
    "            beta_s.append(pm.Normal('beta_%d_im'%(n//2), mu=1., sd = 5.))\n",
    "        #for n in range(0,len(omega)):\n",
    "        #    beta_s.append(BoundNormal('beta_amp_%d'%n,mu=1., sd=10.))\n",
    "        #    #beta_s.append(pm.Uniform('beta_amp_%d'%n,lower=0, upper=30))\n",
    "        #    beta_s.append(pm.Uniform('beta_phs_%d'%n, lower=-np.pi, upper=np.pi))\n",
    "\n",
    "        ###\n",
    "        # Generate the likelihood function using the deterministic variable as the mean\n",
    "        #mu_x = cosine_model_pm(beta_s, omega, dtime)\n",
    "        #mu_x = pm.Deterministic('mu_x', cosine_model_pm(beta_s, omega, dtime))\n",
    "        mu_x = sine_model_notrend_pm(beta_s, omega, dtime)\n",
    "\n",
    "        \n",
    "        #sigma = BoundNormal('sigma', mu=1.,sd=0.25)\n",
    "        #sigma = pm.HalfNormal('sigma',5.)\n",
    "        \n",
    "        #sigma = 1.0\n",
    "        #X_obs = pm.Normal('X_obs', mu=mu_x, sd=sigma, observed=X)\n",
    "        #X_obs = pm.Normal('X_obs', mu=mu_x, sd=1, observed=X)\n",
    "        \n",
    "        # Use an autoregressive model for the error term\n",
    "        beta = pm.Normal('beta', mu=0, sigma=1., shape=arn)\n",
    "        sigma = pm.InverseGamma('sigma',1,1)\n",
    "\n",
    "        #err = pm.AR('err', beta, sigma=sigma, shape=nt)\n",
    "\n",
    "        #sigma = pm.HalfNormal('sigma',1.)\n",
    "        #X_obs = pm.Normal('X_obs', mu=mu_x+err, sd=sigma, observed=X)\n",
    "        X_obs = pm.AR('X_obs', beta, sigma=sigma, observed=X - mu_x)\n",
    "        \n",
    "        #mp = pm.find_MAP()\n",
    "        #print(mp)\n",
    "        \n",
    "        # Inference step...\n",
    "        #step = pm.Metropolis()\n",
    "        #step = pm.NUTS()\n",
    "        step = None\n",
    "        start = None\n",
    "        trace = pm.sample(500, tune=1000, start = start, step=step, cores=2,\n",
    "                         return_inferencedata=False)#nuts_kwargs=dict(target_accept=0.95, max_treedepth=16, k=0.5))\n",
    "        \n",
    "        #trace = None # For testing\n",
    "        \n",
    "        #prior = pm.sample_prior_predictive()\n",
    "        \n",
    "        # Ouput an arviz object\n",
    "        #ds_az = az.from_pymc3(prior=prior)\n",
    "\n",
    "        \n",
    "    \n",
    "    \n",
    "    # Return the trace and the parameter stats\n",
    "    return trace,  my_model, omega, dtime, h_lsq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# tidecons = ['M2','S2','N2','K2','K1','O1','P1','Q1','MA2','MB2']\n",
    "# tidecons = ['M2','S2',] # Non-station harmonics\n",
    "# # tidecons = ['M2','S2',]\n",
    "# tidecons_2 = ['N2','K1','O1'] # Stationary harmonics\n",
    "\n",
    "# frq,names = getTideFreq(tidecons)\n",
    "# frq2,names = getTideFreq(tidecons_2)\n",
    "\n",
    "\n",
    "# # Add on long-term modulations\n",
    "# tdaysec = 86400\n",
    "# fA = 2*np.pi/(365*tdaysec)\n",
    "# # fSA = 2*np.pi/(182*tdaysec)\n",
    "# # fTA = 2*np.pi/(120*tdaysec)\n",
    "# # f90 = 2*np.pi/(90*tdaysec)\n",
    "\n",
    "# # longperiods = [0, fA, fSA, fTA]\n",
    "# #longperiods = [0, 2*np.pi/(365*tdaysec), 2*np.pi/(182*tdaysec), 2*np.pi/(120*tdaysec)]\n",
    "# # longperiods = [0, 2*np.pi/(182*tdaysec),]\n",
    "# #longperiods = [0,  2*np.pi/(120*tdaysec), 2*np.pi/(30*tdaysec)]\n",
    "# # longperiods = [-fTA, -fSA, -fA, 0, fA, fSA, fTA]\n",
    "# # longperiods = [0, fA, fSA]\n",
    "# longperiods = [-3*fA, -2*fA, -1*fA, 0, 1*fA, 2*fA, 3*fA]\n",
    "\n",
    "# # longperiods = [-4*fA, -3*fA, -2*fA, 0, 2*fA, 3*fA, 4*fA]\n",
    "\n",
    "# sitename = 'M2S2nonstat_N2K1O1'\n",
    "# #sitename = 'M2S2_lowfreq_90d'\n",
    "# # outputh5 = '../inputs/a0_samples_harmonicfit_M2S2lowfreq_ATASA_12month.h5'\n",
    "# outputh5 = '../inputs/a0_samples_harmonicfit_{}_12month.h5'.format(sitename)\n",
    "# #outputh5 = '../inputs/a0_samples_harmonicfit_M2S2K1O1lowfreq_12month.h5'\n",
    "\n",
    "# frq_lt = []\n",
    "# for ff in frq:\n",
    "#     for ll in longperiods:\n",
    "#         frq_lt.append(ff+ll)\n",
    "        \n",
    "# # Append the stationary harmonics\n",
    "# for ff in frq2:\n",
    "#     frq_lt.append(ff)\n",
    "\n",
    "######\n",
    "\n",
    "# \n",
    "# tidecons = ['M2','S2','N2','K1','O1'] # Non-stationary harmonics\n",
    "# number_annual_harmonics = 3\n",
    "# sitename = 'M2S2N2K1O1_nonstat_AR1'\n",
    "\n",
    "tidecons = ['M2','S2','N2','K1','O1'] # Tidal harmonic\n",
    "number_annual_harmonics = 0\n",
    "arn = 4\n",
    "sitename = 'M2S2N2K1O1_na{}_AR{}_dt20min'.format(number_annual_harmonics, arn)\n",
    "\n",
    "\n",
    "# tidecons = ['M2','S2',]\n",
    "\n",
    "frq,names = getTideFreq(tidecons)\n",
    "\n",
    "# Add on long-term modulations\n",
    "tdaysec = 86400\n",
    "fA = 2*np.pi/(365.25*tdaysec)\n",
    "#longperiods = [-3*fA, -2*fA, -1*fA, 0, 1*fA, 2*fA, 3*fA]\n",
    "\n",
    "longperiods=[]\n",
    "for n in range(-number_annual_harmonics, number_annual_harmonics+1):\n",
    "    longperiods.append(n*fA)\n",
    "\n",
    "# longperiods = [-4*fA, -3*fA, -2*fA, 0, 2*fA, 3*fA, 4*fA]\n",
    "\n",
    "# sitename = 'M2S2N2K1O1nonstat'\n",
    "\n",
    "#sitename = 'M2S2_lowfreq_90d'\n",
    "# outputh5 = '../inputs/a0_samples_harmonicfit_M2S2lowfreq_ATASA_12month.h5'\n",
    "# outputh5 = '../inputs/a0_samples_harmonicfit_{}_12month.h5'.format(sitename)\n",
    "\n",
    "#outputh5 = '../inputs/a0_samples_harmonicfit_M2S2K1O1lowfreq_12month.h5'\n",
    "\n",
    "frq_lt = []\n",
    "for ff in frq:\n",
    "    for ll in longperiods:\n",
    "        frq_lt.append(ff+ll)\n",
    "        \n",
    "######\n",
    "# sitename = 'M2S2N2K2K1O1P1Q1'\n",
    "# outputh5 = '../inputs/a0_samples_harmonicfit_{}_12month.h5'.format(sitename)\n",
    "# tidecons = ['M2','S2','N2','K2','K1','O1','P1','Q1']\n",
    "# # # tidecons = ['M2','S2','N2','K2','K1','O1','P1','Q1','MA2','MB2']\n",
    "# frq_lt,names = getTideFreq(tidecons)\n",
    "\n",
    "#####\n",
    "\n",
    "basetime = datetime(2016,1,1)\n",
    "\n",
    "# X_sd = A_n_1h.y.std()\n",
    "# X_mu = A_n_1h.y.mean()\n",
    "\n",
    "X_sd = 1\n",
    "X_mu = 0\n",
    "\n",
    "idx = ~np.isnan(A_n_1h.values)\n",
    "X = A_n_1h.values[idx] - X_mu\n",
    "X /= X_sd\n",
    "\n",
    "timein = A_n_1h.time.values[idx]\n",
    "\n",
    "# trace, my_model, omega, dtime, h_lsq = harmonic_fit_mcmc(A_n_1h.time.values[idx], X, frq_lt, basetime=basetime)\n",
    "trace, my_model, omega, dtime, h_lsq = harmonic_fit_mcmc_arn(timein, X, frq_lt,\\\n",
    "                                                             arn=arn, basetime=basetime)\n",
    "\n",
    "pm.summary(trace)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed prediction time\n",
    "rhotime = pd.date_range('2016-05-01','2017-05-02',freq='1H').values\n",
    "rhotime.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ar_sample(dtime, omega, trace, use_ar=True):\n",
    "    true_center = 0.\n",
    "    T = dtime.shape[0]\n",
    "    y = np.zeros((T,))\n",
    "    \n",
    "    arn = trace['beta'].shape[0]\n",
    "    \n",
    "    if use_ar:\n",
    "        for t in range(arn, T):\n",
    "            for ii in range(arn):\n",
    "                y[t] += trace['beta'][ii] * y[t - ii- 1] \n",
    "            y[t] += np.random.normal(loc=true_center, scale=trace['sigma'])\n",
    "    \n",
    "    betas = [trace['beta_mean']]\n",
    "    nomega = len(omega)\n",
    "    for ii in range(nomega):\n",
    "        betas.append(trace['beta_{}_re'.format(ii)])\n",
    "        betas.append(trace['beta_{}_re'.format(ii)])\n",
    " \n",
    "    # Add on an oscillatory component\n",
    "    mu = sine_model_notrend(betas, omega, dtime)\n",
    "    y+=mu\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output the data at a new time\n",
    "tnew = rhotime\n",
    "tsecnew = SecondsSince(tnew,basetime=basetime)\n",
    "tdaynew = tsecnew/86400.\n",
    "\n",
    "y_ar = []\n",
    "for tt in trace:\n",
    "    y_ar.append(generate_ar_sample(tdaynew, omega, tt, use_ar=True))\n",
    "    \n",
    "y_no_ar = generate_ar_sample(tdaynew, omega, trace[200], use_ar=False)\n",
    "\n",
    "a0_pred = np.array(y_ar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(dtime, X,'r--',lw=0.5)\n",
    "plt.plot(tdaynew, y_ar[10],'0.5', lw=0.5,)\n",
    "plt.plot(tdaynew, y_no_ar,'b',lw=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the data to arviz structure and save\n",
    "\n",
    "# ds = az.from_pymc3_predictions({'a0':a0_pred})\n",
    "\n",
    "# Save the predictions\n",
    "dims = ('chain','draw','time')\n",
    "ds = az.from_pymc3_predictions({'a0':a0_pred}, \\\n",
    "                coords={'time':tnew,'chain':np.array([1])}, dims={'a0':dims})\n",
    "\n",
    "# Save the posterior\n",
    "ds2 = az.from_pymc3(trace=trace)\n",
    "\n",
    "# Update the observed data becuase it comes out as a theano.tensor in the way\n",
    "# our particular model is specified\n",
    "ds2.observed_data['X_obs'] = xr.DataArray(X, dims=('time',), coords={'time':timein})\n",
    "\n",
    "# This merges the data sets\n",
    "ds2.extend(ds)\n",
    "ds2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data to netcdf\n",
    "outputnc = '../inputs/a0_samples_harmonicfit_{}_12month.nc'.format(sitename)\n",
    "ds2.to_netcdf(outputnc)\n",
    "print(outputnc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test loading the data (use xarray)\n",
    "xr.open_dataset(outputnc,'predictions')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# tnew = rhotime\n",
    "# tsecnew = SecondsSince(tnew,basetime=basetime)\n",
    "# tdaynew = tsecnew/86400.\n",
    "# tdays.set_value(tdaynew)\n",
    "\n",
    "tnew = A_n_1h.time.values[idx]\n",
    "# Use the built-in function for prediction\n",
    "nsamples = 500\n",
    "ppc = pm.sample_posterior_predictive(trace, model=my_model, samples=nsamples)\n",
    "\n",
    "a0_pred = ppc['X_obs']*X_sd + X_mu\n",
    "\n",
    "err = np.median(a0_pred,axis=0) - A_n_1h.values[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "ax1=plt.subplot(211)\n",
    "plt.plot(tnew, np.median(a0_pred,axis=0),'b--')\n",
    "plt.fill_between(tnew, np.percentile(a0_pred,2.5,axis=0),\\\n",
    "                 np.percentile(a0_pred,97.5,axis=0),color='b',alpha=0.5)\n",
    "\n",
    "#plt.plot(tnew, trace['err'].mean(axis=0),'k')\n",
    "\n",
    "A_n_1h.plot(color='r',ls='--',lw=0.5)\n",
    "\n",
    "plt.subplot(212,sharex=ax1, sharey=ax1)\n",
    "plt.plot(tnew, np.median(a0_pred,axis=0),'b--')\n",
    "\n",
    "# plt.plot(tnew, err,'r',lw=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "\n",
    "A_n_1h.plot(color='r',ls='--',lw=0.5)\n",
    "\n",
    "plt.plot(tnew, np.median(a0_pred,axis=0),'b',lw=0.5)\n",
    "plt.fill_between(tnew, np.percentile(a0_pred,2.5,axis=0),\\\n",
    "                 np.percentile(a0_pred,97.5,axis=0),color='0.5',alpha=0.5)\n",
    "\n",
    "plt.ylim(-40,40)\n",
    "plt.xlim(datetime(2017,1,24),datetime(2017,4,7))\n",
    "# plt.xlim(datetime(2016,7,1),datetime(2016,9,1))\n",
    "\n",
    "plt.grid(b=True)\n",
    "plt.xlabel('Date [yyyy-mm]')\n",
    "plt.ylabel('Amplitude [m]')\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "plt.savefig('../FIGURES/a0_harmonic_zoom_{}.png'.format(sitename),dpi=150)\n",
    "plt.savefig('../FIGURES/a0_harmonic_zoom_{}.pdf'.format(sitename),dpi=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the min/max only\n",
    "a0_mean = np.median(a0_pred,axis=0)\n",
    "idx1 = signal.find_peaks_cwt(a0_mean, np.arange(1,3))\n",
    "idx2 = signal.find_peaks_cwt(-a0_mean, np.arange(1,3))\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(tnew[idx1],a0_mean[idx1],'b.',ms=1)\n",
    "plt.plot(tnew[idx2],a0_mean[idx2],'b.',ms=1)\n",
    "\n",
    "idx1 = signal.find_peaks_cwt(A_n_1h.values, np.arange(1,3))\n",
    "idx2 = signal.find_peaks_cwt(-A_n_1h.values, np.arange(1,3))\n",
    "\n",
    "\n",
    "plt.plot(A_n_1h.time[idx1],A_n_1h.values[idx1],'r.',ms=1)\n",
    "plt.plot(A_n_1h.time[idx2],A_n_1h.values[idx2],'r.',ms=1)\n",
    "\n",
    "plt.fill_between(tnew, np.percentile(a0_pred,2.5,axis=0),\\\n",
    "                 np.percentile(a0_pred,97.5,axis=0),color='0.2',alpha=0.5)\n",
    "\n",
    "plt.ylim(-40,40)\n",
    "plt.xlim(tnew[0],tnew[-1])\n",
    "plt.grid(b=True)\n",
    "plt.xlabel('Date [yyyy-mm]')\n",
    "plt.ylabel('Amplitude [m]')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('../FIGURES/a0_harmonic_timeseries_{}.png'.format(sitename),dpi=150)\n",
    "plt.savefig('../FIGURES/a0_harmonic_timeseries_{}.pdf'.format(sitename),dpi=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the power spectrum with the individual freqencies plus posterior distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_spectra_w(tsec, u_r, window=np.hanning, K=3, power=2., axis=-1):\n",
    "    \"\"\"\n",
    "    Calculates the power spectral density from a real valued quanity\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    M = tsec.shape[0]\n",
    "    dt = tsec[1]-tsec[0]\n",
    "    M_2 = int(np.floor(M/2))\n",
    "      \n",
    "    \n",
    "    h_tk = window(M)\n",
    "    # Weight the time-series and perform the fft\n",
    "    u_r_t = u_r[...,:]*h_tk\n",
    "    S_k = np.fft.fft(u_r_t, axis=axis)\n",
    "    S = dt *np.abs(S_k)**power\n",
    "    #S = np.mean(S_k,axis=-2)\n",
    "        \n",
    "    omega = np.fft.fftfreq(int(M),d=dt/(2*np.pi))\n",
    "    \n",
    "    #domega = 2*np.pi/(M*dt)\n",
    "    domega = 1/(M*dt)\n",
    "    \n",
    "    # Extract the positive and negative frequencies\n",
    "    omega_ccw = omega[0:M_2]\n",
    "    #omega_cw = omega[M_2::] # negative frequencies\n",
    "    S_ccw = S[...,0:M_2]\n",
    "    #S_cw = S[...,M_2::]\n",
    "\n",
    "    return omega_ccw,S_ccw,domega"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolate onto a regular time grid\n",
    "#dt = 3600\n",
    "dt = 60\n",
    "timeinterp = pd.date_range(A_n_1h.time.values[0],A_n_1h.time.values[-1],freq='{}s'.format(dt))\n",
    "A_n_1h_i = A_n.to_xray().interp({'time':timeinterp})\n",
    "#A_n_1h_i = A_n_1h.interp({'time':timeinterp})\n",
    "\n",
    "\n",
    "tsec = timeinterp.view(int)*1e-9\n",
    "\n",
    "f, S, df = power_spectra(tsec, A_n_1h_i.values, K=1 )\n",
    "fpred, Spred, dfpred = power_spectra(tsecnew, a0_pred[200,:], K=1 )\n",
    "\n",
    "#f, S3, df = power_spectra(tsec, A_n_1h_i.values, K=3)\n",
    "\n",
    "#dt=60\n",
    "fcpd = f*86400/(2*np.pi)\n",
    "fcpd2 = fpred*86400/(2*np.pi)\n",
    "\n",
    "plt.figure()\n",
    "plt.loglog(fcpd,S/(86400/(2*np.pi)), lw=0.5)\n",
    "plt.loglog(fcpd2,Spred/(86400/(2*np.pi)), lw=0.5, alpha=0.5)\n",
    "\n",
    "plt.xlim(1e-1,1e1)\n",
    "# plt.xlim(1.8,2.2)\n",
    "\n",
    "#plt.ylim(1e3,1e9)\n",
    "plt.ylabel('Amplitude Spectrum [m$^2$ cpd$^{-1}$]')\n",
    "plt.xlabel('Frequency [cpd]')\n",
    "plt.grid(b=True,ls=':', which='both')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the power spectrum for the inferred harmonic parameters\n",
    "psd = []\n",
    "amp = []\n",
    "for ii in range(len(omega)):\n",
    "    A = trace['beta_{}_re'.format(ii)] + 1j*trace['beta_{}_im'.format(ii)]\n",
    "    psd.append(np.abs( A*np.conj(A))*86400*dt)\n",
    "    amp.append(np.abs(A))\n",
    "    \n",
    "psd = np.array(psd)\n",
    "amp = np.array(amp)\n",
    "psd_mu = np.median(psd,axis=1)\n",
    "psd_low = np.percentile(psd,5,axis=1)\n",
    "psd_high = np.percentile(psd,95,axis=1)\n",
    "\n",
    "amp_mu = np.median(amp,axis=1)\n",
    "amp_low = np.percentile(amp,5,axis=1)\n",
    "amp_high = np.percentile(amp,95,axis=1)\n",
    "\n",
    "omega_cpd = np.array([ff/(2*np.pi) for ff in omega])\n",
    "\n",
    "yerr = np.stack([amp_mu - amp_low, amp_high-amp_mu])\n",
    "#yerr = amp_high-amp_low\n",
    "yerr.shape, yerr, amp_mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the fft amplitude directly\n",
    "n = A_n_1h_i.values.shape[0]\n",
    "#w = np.hamming(n)\n",
    "#w = np.kaiser(n,8.6)\n",
    "w= np.ones((n,))\n",
    "wsum = 1/(np.sum(w)/n)\n",
    "F = np.fft.fft(A_n_1h_i.values*w)\n",
    "f = np.fft.fftfreq(n,dt)*2*np.pi # Hz\n",
    "fcpd = f*86400/(2*np.pi)\n",
    "#plt.figure()\n",
    "#plt.plot(fcpd,2*np.abs(F)/n)\n",
    "\n",
    "plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "plt.plot(fcpd,2*np.abs(F)/n*wsum,'k',lw=1)\n",
    "#plt.errorbar(omega_cpd, amp_mu, yerr=yerr, c='b',fmt='.')\n",
    "plt.errorbar(omega_cpd, amp_mu, yerr=yerr, c='b', fmt='.', ms=3,ecolor='r')\n",
    "\n",
    "\n",
    "plt.xlim(0.85,2.1)\n",
    "#plt.xlim(1.85,2.05)\n",
    "plt.ylim(1e-2,12.5)\n",
    "plt.ylabel('Amplitude [m]')\n",
    "plt.xlabel('Frequency [cpd]')\n",
    "\n",
    "# inset axes....\n",
    "axins = ax.inset_axes([0.05, 0.35, 0.57, 0.57])\n",
    "\n",
    "axins.plot(fcpd,2*np.abs(F)/n*wsum,'k',lw=1)\n",
    "#plt.plot(fcpd,2*np.sqrt(S3/dt)/(dt*2*np.pi),'k',lw=0.74)\n",
    "\n",
    "axins.errorbar(omega_cpd, amp_mu, yerr=yerr, c='b', fmt='.', ms=3,ecolor='r')\n",
    "\n",
    "# sub region of the original image\n",
    "x1, x2, y1, y2 = 1.85,2.05, 0, 12\n",
    "axins.set_xlim(x1, x2)\n",
    "axins.set_ylim(y1, y2)\n",
    "axins.set_xticklabels('')\n",
    "axins.set_yticklabels('')\n",
    "axins.text(1.89,3,'N2')\n",
    "axins.text(1.935,11,'M2')\n",
    "axins.text(2.0,5,'S2')\n",
    "plt.tight_layout()\n",
    "ax.indicate_inset_zoom(axins)\n",
    "\n",
    "plt.savefig('../FIGURES/a0_spectra_amp_{}.png'.format(sitename),dpi=150)\n",
    "plt.savefig('../FIGURES/a0_spectra_amp_{}.pdf'.format(sitename),dpi=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
